# 概览

## 框架目录结构

```
├── Agent/                     # 主要框架包
│   ├── agents/                # 各类 Agent 实现
│   │   └── review/            # 代码审查 Agent
│   ├── core/                  # 核心模块
│   │   ├── adapter/           # LLM/工具适配层
│   │   ├── context/           # 上下文管理
│   │   ├── llm/               # 大模型客户端
│   │   ├── logging/           # 日志模块
│   │   ├── state/             # 会话/状态管理
│   │   ├── stream/            # 流式处理
│   │   └── tools/             # 工具运行时
│   ├── domain/                # 领域模型（可扩展）
│   ├── examples/              # 示例/演示脚本
│   └── tool/                  # 工具注册与管理
├── DIFF/                      # Diff 相关处理
│   ├── rule/                  # Diff 规则
│   └── diff_collector.py      # Diff 收集器
├── log/                       # 审查/接口日志
│   ├── api_log/
│   └── diff_log/
├── requirements.txt           # 依赖声明
```

## 核心模块职责

* diff_collector.py

职责：

从 Git 里抽取本次要审查的变更

关键点：

支持三种模式：

staged（当前暂存区）

working（工作区未提交）

range（两个 commit / 分支之间）

使用 unidiff 解析 diff

输出：List[ReviewUnit]

* rule/context_decision.py

职责：

基于 ReviewUnit 的度量信息（metrics）、标签（tags）、语言类型等，给出“应该看多大范围上下文、是否需要调用额外上下文 Agent”的决策。

关键点：

- 核心结构：
  - ReviewUnit：单个变更单元（文件 + hunk + before/after/context + metrics + tags）。
  - RuleSuggestion：规则层对单个 ReviewUnit 的建议（上下文级别、优先级、关注维度等）。
  - AgentDecision：汇总后的决策，用于告诉 Agent 是否需要拉取更多上下文、是否需要工具等。
- 规则示例：
  - 只改 import、配置文件：偏“轻量审查”，上下文可收缩。
  - 大量业务逻辑、复杂函数：需要更多上下文、优先调用 read_file_hunk / search_in_project。
  - 安全敏感 / 配置变更：提高优先级，提醒 LLM 做安全、兼容性审查。

* Agent/core/context/diff_provider.py

职责：

把 diff_collector 输出的 ReviewUnit 转换成“LLM 友好”的上下文结构，并按文件、变更片段组织。

关键点：

- 提供 `DiffContext`：
  - `summary`：用于提示词的 `[Diff Summary]`（包含文件名、变更类型、行范围、简要统计）。
  - `files`：本次涉及的文件列表，供工具 / Agent 决策使用。
  - `units`：原始 ReviewUnit 列表，后续可用于更精细的上下文调度。
- 与规则层（context_decision）结合，未来可以做到：
  - 对重要变更拉取更多上下文。
  - 对简单变更减少 token 占用。

* Agent/core/llm/client.py

职责：

对接不同厂商的大模型 API，并统一为“流式 token + usage + tool_calls”风格。

关键点：

- MoonshotLLMClient（Kimi 系列）：
  - 使用官方 OpenAI 兼容接口 `/chat/completions`。
  - 支持 `stream=True` 的 SSE 流式输出。
  - 原样透传 message.content & tool_calls（包括 arguments 的分片）。
- GLMLLMClient（智谱 GLM4.6）：
  - 按智谱官方文档适配，同样输出 Moonshot 风格的流式 delta。
- MockMoonshotClient：
  - 本地模拟模型返回，方便脱网测试工具调用/流式解析。
- 所有客户端都通过 APILogger 记录：
  - REQUEST：url + payload。
  - RESPONSE_CHUNK：原始流式行 + 解析后的 JSON。
  - RESPONSE：非流式完整 JSON。

* Agent/core/stream/stream_processor.py

职责：

把厂商各自的流式 delta 归一化为内部“私有格式”，是整个 Agent 主循环的唯一入口格式。

关键点：

- 私有格式 NormalizedMessage：
  - `type` / `role` / `content`
  - `tool_calls`: List[NormalizedToolCall]
    - `id` / `name` / `index` / `arguments`（已反序列化的 dict，损坏 JSON 兜底为 `_raw`）
  - `finish_reason`: "stop" | "tool_calls" | ...
  - `usage`: 本次请求的 token 统计（input/output/total），用于 GUI 展示。
  - `raw`: 原始分片，便于调试。
- 支持：
  - arguments 分片拼接。
  - 多个 tool_calls，按 index 归并。
  - message.content 在工具阶段非空的情况（解释调用哪些工具、为什么）。

* Agent/core/adapter/llm_adapter.py

职责：

在 LLM 客户端之上，再加一层适配，使不同厂商的 API 对 Agent 来说完全统一。

关键点：

- ToolDefinition：内部约定的 tools 结构，兼容 OpenAI/Moonshot/GLM 的 function-calling。
- LLMAdapter：
  - 默认使用 `stream_chat` + StreamProcessor.collect。
  - 对外只暴露 NormalizedMessage。
- KimiAdapter：
  - 在流式模式下，直接复用基类逻辑。
  - 在非流式模式下，显式解析 `response.choices[0].message.tool_calls` 到 NormalizedToolCall。

* Agent/core/state/conversation.py

职责：

管理对话消息 messages[]，让 LLM 在工具轮回中保持上下文一致，并为未来多轮对话打基础。

关键点：

- 支持 role = system/user/assistant/tool。
- add_assistant_message：
  - 把内部 NormalizedToolCall 重新编码为 API 需要的 `"tool_calls": [{"id","type","function":{name,arguments(str)}}]`。
  - arguments 统一序列化为字符串 JSON。
- add_tool_result：
  - 追加 `"role": "tool"` 消息，包含 tool_call_id / name / content / error。
- prune_history：
  - 预留历史裁剪能力，未来可以根据 token 预算智能截断对话。

* Agent/core/tools/runtime.py & Agent/tool/registry.py

职责：

提供统一的“工具运行时 + 注册中心”，让 LLM 只面向声明式工具列表，而不关心实现细节。

关键点：

- ToolRuntime：
  - register(name, func) 注册工具实现。
  - execute(tool_calls) 并发执行工具调用，返回标准化的 tool 消息：
    - `{"tool_call_id", "name", "content", "error"}`。
  - 错误兜底：任何异常被捕获到 error 字段，不让 Agent 崩溃。
- registry：
  - 以 ToolSpec 形式集中管理工具：name/description/parameters/func。
  - 当前内置工具：
    - echo_tool：回显文本，方便调试 Agent 逻辑。
    - list_project_files：基于 git ls-files，列出项目文件（尊重 .gitignore）。
    - read_file_hunk：按行号读取文件片段，用于补充 diff 上下文。
    - read_file_info：返回大小、语言、行数、是否测试/配置文件。
    - search_in_project：基于 git grep 做代码搜索（调用链、变量定义等）。
    - get_dependencies：扫描 requirements.txt / package.json / pyproject.toml 等依赖信息。
  - 所有工具统一出现在 GUI / CLI 中，禁止硬编码。

* Agent/agents/review/code_reviewer.py

职责：

实现单 Agent 的“工具驱动审查”主循环，把 LLM 的 tool_calls 转换为本地调用并形成多轮问答。

关键点：

- 主循环逻辑：
  - 组装 system 提示 + 用户 prompt + diff 上下文。
  - 调用 adapter.complete，获得 NormalizedMessage。
  - 根据 tool_calls & finish_reason 分三种情况：
    1）有 tool_calls：
       - 划分白名单工具（auto_approve_tools）与需要用户审批的工具。
       - 通过 tool_approver（CLI 问答 / GUI 弹窗）确认后执行本地 ToolRuntime。
       - 把工具结果作为 role=tool 消息追加到 ConversationState，继续下一轮 LLM 调用。
    2）无工具调用且 finish_reason=="stop"：
       - 直接返回最终审查结论文本。
    3）非 stop 但无工具：
       - 当前版本简单返回，未来可调整为继续追问。

* Agent/examples/run_agent.py & Agent/examples/gui.py

职责：

为 CLI / GUI 提供“可观测的”交互入口，方便调试、演示与后续比赛展示。

关键点：

- CLI：
  - 自动从 DIFF/diff_collector 收集本次变更，构造 `[Diff Summary]` 提示。
  - 支持 `--tools` / `--auto-approve` 控制工具暴露与自动批准列表。
  - 非交互环境下默认 auto-approve 所有工具，避免阻塞。
- GUI（临时版）：
  - 支持选择模型（GLM / Moonshot / Mock）。
  - 动态加载 registry 中的工具，勾选后暴露给 LLM。
  - 支持“自动批准勾选工具”与“弹窗审批非白名单工具”。
  - 实时展示流式输出，并在状态栏显示：
    - 本次调用 token（input/output/total）。
    - 会话累积 token（input/output/total），为成本控制提供直观反馈。

* 日志体系（Agent/core/logging/api_logger.py & log/）

职责：

记录所有对 LLM 的请求与响应（包括流式分片），作为调试与审计基础。

关键点：

- 每次调用生成独立日志文件，存放于 `log/api_log/`。
- 使用“段结构”：
  - REQUEST
  - RESPONSE_HEADERS
  - RESPONSE_CHUNK（流式）
  - RESPONSE（非流式）
- 便于复盘：
  - 确认 tools 是否正确传递。
  - 对齐厂商真实返回格式，避免想当然。

## 技术框架概览

（略，未来如需对外说明再补充架构图与流程图。）

## Web UI 相关备注（临时设计，后续重做）

- 当前的 Web 部分（`Agent/web/server.py` + `Agent/web/static/`）只是为了验证 SSE 流式接口和 token 统计而快速搭的 Demo：  
  - 页面布局与交互流程非常简陋，仅适合作为开发期调试面板；  
  - 很多功能直接复用 CLI/GUI 语义，没有针对 Web 做专门的 UX 设计。
- 正式版计划（尚未开始）：
  - 重新设计 Web UI 的信息架构：项目选择、变更列表、审查结果与工具调用可视化；  
  - 把当前 server 视为“API 包装层”，保留 `/api/review/start` 协议，但前端实现可以完全推倒重来；  
  - 在 Web 端增加针对审查结果的筛选/标注能力，用于后续评测与多 Agent 调度。

> 结论：当前 Web 页面视为临时实现，仅保证功能可用，不追求体验；后续正式 UI 重做时，可以基于 `Agent/ui/service.py` 提供的接口自由设计。

从上到下，整个系统可以概括为四层：

1. 感知层（Diff + 规则）
   - DIFF/diff_collector.py：从 Git 获取变更，构建 ReviewUnit。
   - rule/context_decision.py：基于 ReviewUnit 的 metrics/tags 等做规则决策。
2. 上下文与工具层
   - Agent/core/context/*：把 ReviewUnit 聚合为 DiffContext，决定喂给 LLM 的上下文。
   - Agent/core/tools/runtime.py + Agent/tool/registry.py：提供可控、可审批的工具执行环境。
3. LLM 适配层
   - Agent/core/llm/client.py：对接 Moonshot / GLM / Mock，拉平 API 差异。
   - Agent/core/stream/stream_processor.py：解析流式返回，输出统一 NormalizedMessage。
   - Agent/core/adapter/llm_adapter.py：给上层只暴露统一接口（complete）。
4. 交互与展示层
   - Agent/agents/review/code_reviewer.py：单 Agent 主循环，实现“工具驱动审查”。
   - Agent/examples/run_agent.py / gui.py：CLI + GUI，用于测试、演示与比赛现场演示。

这四层之间通过“结构化数据”解耦（ReviewUnit / DiffContext / NormalizedMessage / ToolSpec），避免直接耦合具体厂商或具体 UI。

* # v1.5

  > LLM承担整个代码审查系统的职责

  - [x] 当前阶段

  先把范围钉死：

  做一个「单 Agent + 工具 + 规则驱动上下文」的代码审查引擎。

  输入：

  本地 Git 仓库

  目标分支（如 main）

  当前工作区或某个 commit / PR 的 diff

  输出：

  结构化审查结果（JSON）：issues[] + summary

  不上多 Agent，不上复杂协作，先把这一条链路打穿。

  ---

  当前问题：

  ## 上下文策略

  现在的策略本质是：
  
  - 开头：把「整段 diff 概览 + 一些 JSON 摘要」一次性塞进首轮消息。
  - 后续：不再自动补上下文，只让 LLM 自己用工具拉更多代码。
  - 消息：所有轮次、工具结果全堆 messages，不做裁剪、不做摘要。

  这带来几个问题：
  
  1. **第一轮太胖**：首轮 prompt + diff 概览 已经吃掉大量 token，后面再加工具结果，很容易冲 token 上限。
  2. **上下文调度是“放养模式”**：
     - LLM 要是“勤快”，就会疯狂 call 工具，token 爆炸。
     - 要是“懒”，就自己瞎猜，审查质量不稳定。
  3. **对话历史纯堆积**：没有“什么该留下、什么可以摘要”的策略，后续每轮都背负所有历史。
  4. **注意力不集中**：当前链路是 system → user(含 diff markdown/json) → assistant → tool → assistant… 消息会累积；当总长度逼近模型上下文上限时，模型会截断最早的内容，或者虽未截断但权重变低，因此首条 diff 可能被遗忘或被忽略。
  
  > 做到这里感受到单Agent的极限状态了，接下来考虑使用多Agent进行协作

# V2.0

> 承认 LLM 只是引擎，代码审查由不同职能的Agent统筹进行





# 3.0

仔细研究了向量库的具体应用后，发现“为整个代码库构建向量库”理论上可行，但放在 PR 审查这个场景里，本质上在工程层面不合理、没必要、而且会拖垮整个系统性能。

但是——
向量库在“长期项目认知 / 跨文件知识”层面依然有用，只是不能放在实时审查链路里。

1. 构建一个代码库的向量库需要：

遍历所有文件

embedding 所有函数/类

写入向量数据库

这一步对大型代码库（>3万行）耗时：

几秒到几十秒

甚至几分钟

而 PR 审查的要求是：

➤ 改了两行代码
➤ 马上给结果

审查系统不能每次 PR 都重新构建全量向量库。

2. PR 审查只需要小范围上下文，不需要全库语义搜索

PR 的核心需求是：

我改了什么

影响哪里

周边上下文是什么

相关调用链是什么

这些信息：

规则层 + 轻量静态分析
就足够了。

向量检索像是：

“我要找到语义上相似的函数/模式”

但 PR 审查不是在找“相似函数”，
是在找“关联函数”。

两者完全不同。

结构化代码分析 ≫ 向量搜索

3. 代码不适合做 “全量 embedding → 语义检索”

因为：

两段代码语义类似 ≠ 它们之间存在真实调用/依赖关系

embedding 算法对代码依赖极度不敏感

搜索结果往往不相关

会带来大量噪音

反而误导审查 Agent

你要的是准确性，不是泛搜索。

## 那向量库到底该不该做？

该，但不是现在 

真正合理的方式是：

用向量库做“长期项目记忆（Project Memory）”

可以做一个异步的、间歇式的、非实时向量库：

用途包括：

跨文件知识的补全

团队惯用模式识别

项目架构理解（长期累计）

Function/Class 索引

“相关模块”的辅助判断

非 PR 场景的智能 IDE 助手能力

而不是：

 每个 PR 审查都实时构建并查向量库

 最合理的设计是“两层式

第一层（实时审查层）— 不用向量库

适用于 PR 审查、提交前审查

来源：

diff

函数/类上下文

同文件 / 同模块文件

规则层关联文件

工具调用 (read_file/search/scanner)

这部分必须：

轻量

确定性

快

可控

第二层（后台语义层）— 向量库 + 长期索引

适用于：

IDE 整体项目理解

复杂审查的高级模式

多 Agent 的长期知识

跨文件语义引用

项目级建议（架构问题、一致性问题）

这个层可以异步构建：

每次代码库变化时刷新部分 embedding

每日一次增量构建

或者手动触发

供 Agent 在需要时调用：

“给我找跟这个类相关的实现模式”

“找一下类似函数是怎么处理异常的”

“找与这个API相似的模块”


### 总结：

向量库 ≠ PR 审查上下文的核心
向量库 = “长期语义记忆”

实时审查靠规则、diff、结构化上下文；
长期智能靠向量检索。

所以将向量库构建设计在第三版
