"""è¿è¡Œä»£ç å®¡æŸ¥ Agent çš„ç¤ºä¾‹å…¥å£ã€‚"""

from __future__ import annotations

import asyncio
import os
import sys
from pathlib import Path
import argparse
from typing import Any, List, Tuple, Callable
import json

try:
    from dotenv import load_dotenv
except ImportError:  # pragma: no cover - å¯é€‰ä¾èµ–
    def load_dotenv() -> None:
        return None

ROOT = Path(__file__).resolve().parents[2]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

def _inject_venv_sitepackages() -> None:
    candidates = [
        ROOT / "venv" / "Lib" / "site-packages",
    ]
    candidates.extend((ROOT / "venv" / "lib").glob("python*/site-packages"))
    for path in candidates:
        if path.exists() and str(path) not in sys.path:
            sys.path.insert(0, str(path))

_inject_venv_sitepackages()

load_dotenv()

from Agent.agents import (
    PlanningAgent,
    DEFAULT_USER_PROMPT,
    CodeReviewAgent,
    fuse_plan,
    build_context_bundle,
)
from Agent.core.logging import get_logger
from Agent.core.logging.fallback_tracker import (
    fallback_tracker,
    record_fallback,
)
from Agent.core.logging.pipeline_logger import PipelineLogger
from Agent.core.adapter.llm_adapter import KimiAdapter, ToolDefinition
from Agent.core.stream.stream_processor import NormalizedToolCall
from Agent.core.context.provider import ContextProvider
from Agent.core.context.diff_provider import (
    collect_diff_context,
    build_markdown_and_json_context,
)
from Agent.core.logging.context import generate_trace_id
from Agent.core.llm.client import (
    BaseLLMClient,
    BailianLLMClient,
    GLMLLMClient,
    MockMoonshotClient,
    MoonshotLLMClient,
)
from Agent.core.logging.api_logger import APILogger
from Agent.core.state.conversation import ConversationState
from Agent.core.stream.stream_processor import StreamProcessor
from Agent.core.tools.runtime import ToolRuntime
from Agent.tool.registry import (
    builtin_tool_names,
    default_tool_names,
    get_tool_functions,
    get_tool_schemas,
)

logger = get_logger(__name__)


def create_llm_client(trace_id: str | None = None) -> Tuple[BaseLLMClient, str]:
    glm_key = os.getenv("GLM_API_KEY")
    if glm_key:
        try:
            return GLMLLMClient(
                model=os.getenv("GLM_MODEL", "GLM-4.6"),
                api_key=glm_key,
                logger=APILogger(trace_id=trace_id) if trace_id else None,
            ), "glm"
        except Exception as exc:
            print(f"[è­¦å‘Š] GLM å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼š{exc}")
            record_fallback(
                "llm_client_fallback",
                "GLM åˆå§‹åŒ–å¤±è´¥ï¼Œç»§ç»­å°è¯•å…¶ä»–æ¨¡å‹",
                meta={"provider": "glm", "error": str(exc)},
            )

    bailian_key = os.getenv("BAILIAN_API_KEY")
    if bailian_key:
        try:
            return (
                BailianLLMClient(
                    model=os.getenv("BAILIAN_MODEL", "qwen-max"),
                    api_key=bailian_key,
                    base_url=os.getenv("BAILIAN_BASE_URL"),
                    logger=APILogger(trace_id=trace_id) if trace_id else None,
                ),
                "bailian",
            )
        except Exception as exc:
            print(f"[è­¦å‘Š] Bailian å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼š{exc}")
            record_fallback(
                "llm_client_fallback",
                "Bailian åˆå§‹åŒ–å¤±è´¥ï¼Œç»§ç»­å°è¯•å…¶ä»–æ¨¡å‹",
                meta={"provider": "bailian", "error": str(exc)},
            )

    try:
            return (
                MoonshotLLMClient(
                    model=os.getenv("MOONSHOT_MODEL", "kimi-k2.5"),
                    logger=APILogger(trace_id=trace_id) if trace_id else None,
                ),
                "moonshot",
            )
    except (ValueError, RuntimeError) as exc:
        print(f"[è­¦å‘Š] Moonshot å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼š{exc}")
        record_fallback(
            "llm_client_fallback",
            "Moonshot åˆå§‹åŒ–å¤±è´¥ï¼Œé™çº§ä¸º Mock",
            meta={"provider": "moonshot", "error": str(exc)},
        )
        return MockMoonshotClient(), "mock"


def console_tool_approver(calls: List[NormalizedToolCall]) -> List[NormalizedToolCall]:
    approved: List[NormalizedToolCall] = []
    for call in calls:
        name = call.get("name")
        args = call.get("arguments")
        arg_text = args if isinstance(args, str) else json.dumps(args, ensure_ascii=False)
        print(f"\n[å·¥å…·è¯·æ±‚] {name}\nå‚æ•°: {arg_text}")
        choice = input("ğŸ‘€ æ‰§è¡Œè¯¥å·¥å…·å—? [y/N]: ").strip().lower()
        if choice.startswith("y"):
            approved.append(call)
    return approved


async def main() -> None:
    parser = argparse.ArgumentParser(description="Run the code review agent.")
    parser.add_argument(
        "--prompt",
        default=DEFAULT_USER_PROMPT,
        help="Prompt sent to the agent (willè¢«é™„åŠ åœ¨ diff ä¸Šä¸‹æ–‡å‰é¢ï¼‰ã€‚",
    )
    parser.add_argument(
        "--tools",
        nargs="*",
        default=None,
        help="Tool names to expose (default: current registry).",
    )
    parser.add_argument(
        "--auto-approve",
        nargs="*",
        default=None,
        help="Tool names that can run without manual approval.",
    )
    args = parser.parse_args()

    fallback_tracker.reset()
    trace_id = generate_trace_id()
    client, provider_name = create_llm_client(trace_id=trace_id)
    tool_names = args.tools or default_tool_names()
    adapter = KimiAdapter(client, StreamProcessor(), provider_name=provider_name)
    pipe_logger = PipelineLogger(trace_id=trace_id)

    try:
        diff_ctx = collect_diff_context()
    except Exception as exc:
        print(f"[é”™è¯¯] æ— æ³•æ”¶é›† diff: {exc}")
        return
    logger.info(
        "diff collected mode=%s files=%d units=%d",
        diff_ctx.mode.value,
        len(diff_ctx.files),
        len(diff_ctx.units),
    )
    session_log = pipe_logger.start("planning_review", {"provider": provider_name, "trace_id": trace_id})
    pipe_logger.log(
        "diff_summary",
        {
            "mode": diff_ctx.mode.value,
            "files": len(diff_ctx.files),
            "units": len(diff_ctx.units),
            "review_index_units": len(diff_ctx.review_index.get("units", [])),
            "review_index_preview": diff_ctx.review_index.get("units", [])[:3],
        },
    )

    # è§„åˆ’é“¾è·¯ï¼šåªæ¶ˆè´¹å…ƒæ•°æ®ç´¢å¼•ï¼Œè¾“å‡ºä¸Šä¸‹æ–‡è®¡åˆ’
    planner_state = ConversationState()
    planner = PlanningAgent(adapter, planner_state, logger=pipe_logger)
    plan = await planner.run(diff_ctx.review_index)
    fused = fuse_plan(diff_ctx.review_index, plan)
    context_bundle = build_context_bundle(diff_ctx, fused)
    logger.info(
        "plan fused provider=%s plan_units=%d bundle_items=%d",
        provider_name,
        len(plan.get("plan", [])) if isinstance(plan, dict) else 0,
        len(context_bundle),
    )
    pipe_logger.log("planning_output", {"plan": plan})
    pipe_logger.log("fusion_output", {"fused": fused})
    pipe_logger.log(
        "context_bundle_summary",
        {
            "bundle_size": len(context_bundle),
            "unit_ids": [c.get("unit_id") for c in context_bundle],
        },
    )
    print("è§„åˆ’ç»“æœ(JSON):", json.dumps(plan, ensure_ascii=False, indent=2))
    print("èåˆç»“æœ(JSON):", json.dumps(fused, ensure_ascii=False, indent=2))
    print("ä¸Šä¸‹æ–‡åŒ…ï¼ˆå ä½ï¼‰:", json.dumps(context_bundle, ensure_ascii=False, indent=2))

    # å®¡æŸ¥ Agentï¼šæ¶ˆè´¹ ContextBundle ä½œä¸ºä¸Šä¸‹æ–‡
    runtime = ToolRuntime()
    for name, func in get_tool_functions(tool_names).items():
        runtime.register(name, func)
    if not tool_names:
        print("[è­¦å‘Š] æœªå¯ç”¨ä»»ä½•å·¥å…·ï¼Œæœ¬æ¬¡åªä¼šè¾“å‡ºå®¡æŸ¥æ–‡æœ¬ã€‚")

    context_provider = ContextProvider()
    state = ConversationState()
    trace_logger = APILogger(trace_id=trace_id)

    review_index_md, _ = build_markdown_and_json_context(diff_ctx)
    ctx_json = json.dumps({"context_bundle": context_bundle}, ensure_ascii=False, indent=2)
    full_prompt = (
        f"{args.prompt}\n\n"
        f"å®¡æŸ¥ç´¢å¼•ï¼ˆä»…å…ƒæ•°æ®ï¼Œæ— ä»£ç æ­£æ–‡ï¼Œéœ€ä»£ç è¯·è°ƒç”¨å·¥å…·ï¼‰ï¼š\n{review_index_md}\n\n"
        f"ä¸Šä¸‹æ–‡åŒ…ï¼ˆæŒ‰è§„åˆ’æŠ½å–çš„ç‰‡æ®µï¼‰ï¼š\n```json\n{ctx_json}\n```"
    )
    pipe_logger.log(
        "review_request",
        {
            "prompt_preview": full_prompt[:2000],
            "context_bundle_size": len(context_bundle),
        },
    )

    agent = CodeReviewAgent(adapter, runtime, context_provider, state, trace_logger=trace_logger)
    tool_schemas = get_tool_schemas(tool_names)
    default_auto = [name for name in tool_names if name in builtin_tool_names()]
    approver: Callable[[List[NormalizedToolCall]], List[NormalizedToolCall]] | None = None
    if args.auto_approve is None:
        auto_approve = default_auto
        if set(auto_approve) != set(tool_names):
            approver = console_tool_approver
    else:
        auto_approve = args.auto_approve or []
        approver = console_tool_approver

    result = await agent.run(
        prompt=full_prompt,
        files=diff_ctx.files,
        tools=tool_schemas,  # type: ignore[arg-type]  # schema å·²ç¬¦åˆ ToolDefinition
        auto_approve_tools=auto_approve,
        tool_approver=approver,
    )
    pipe_logger.log("review_result", {"result": result})
    fb_summary = fallback_tracker.emit_summary(logger=logger, pipeline_logger=pipe_logger)
    if fb_summary.get("total"):
        print(f"[å›é€€å‘Šè­¦] æœ¬æ¬¡è§¦å‘ {fb_summary['total']} æ¬¡ï¼š{fb_summary['by_key']}")
    pipe_logger.log(
        "session_end",
        {"log_path": str(session_log), "result_preview": (result[:200] if isinstance(result, str) else "")},
    )
    print("Agent result:", result)


if __name__ == "__main__":
    asyncio.run(main())
