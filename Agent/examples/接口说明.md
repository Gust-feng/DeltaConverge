# 前端接入接口说明（审查内核）

本项目的“审查内核”已经抽象出一层与 UI 无关的 Service，路径为：  
`Agent/ui/service.py`  
任何前端（命令行、Tk GUI、Web 页面、VSCode 扩展等）都应该只依赖这一层，而不要直接拼装 LLMClient / Agent / Runtime。

## 一、环境依赖

- Python 3.10+ 建议。  
- 安装依赖：`pip install -r requirements.txt`  
- 可选环境变量（放在 `.env`）：
  - `GLM_API_KEY`（优先使用 GLM4.6）、`GLM_MODEL`（默认：`GLM-4.6`）  
  - `MOONSHOT_API_KEY`、`MOONSHOT_MODEL`（默认：`kimi-k2.5`）  
- 如果两个 KEY 都没有配置，会自动退回到 Mock 模型（本地假数据，便于联调 UI）。

## 二、核心接口（Agent/ui/service.py）

### 0. 链路消歧义（上下文计划）

- 规则层：diff 解析生成 `review_index.units[*].rule_context_level/rule_confidence`。
- 规划 LLM（“上下文 agent”）：读取 review_index，输出 plan JSON（unit_id/llm_context_level/extra_requests/skip_review）。
- 融合：`Agent/agents/fusion.py` 把规则与 LLM 计划融合为 `final_context_level`。
- 上下文拉取：`Agent/agents/context_scheduler.py` 按融合计划组装 ContextBundle（diff/function/file_context/full_file/callers/previous_version 等）。
- 审查 LLM：`CodeReviewAgent` 使用 ContextBundle 生成审查结论。
- `DIFF/rule/context_decision.py` 里的 `decide_context` 仅为旧接口兼容，已不再参与主链路。

### 1. 选择 LLM：`create_llm_client`

```python
from Agent.ui.service import create_llm_client

client, provider_name = create_llm_client("auto")
```

- `preference` 取值：`"auto" | "glm" | "moonshot" | "mock"`  
- 逻辑：  
  - `"auto"`：优先 GLM（如果有 `GLM_API_KEY`），否则 Moonshot，再否则 Mock。  
  - `"glm"`：强制 GLM，没有会抛异常。  
  - `"moonshot"`：强制 Moonshot，没有会抛异常。  
  - `"mock"`：强制使用 Mock 客户端。

通常前端不需要直接用这个函数，`run_review` 内部已经会处理。

### 2. tokens 统计：`UsageAggregator`

前端如果想显示 tokens 消耗（本次调用 + 会话累计），可以使用这个辅助类：

```python
from Agent.ui.service import UsageAggregator

agg = UsageAggregator()
agg.reset()  # 新会话前清空

# 传入 usage 和 call_index
current, totals = agg.update(usage_dict, call_index)
```

- `usage_dict` 来自回调事件中的 `usage` 字段，兼容：
  - `input_tokenss` 或 `prompt_tokenss`
  - `output_tokenss` 或 `completion_tokenss`
  - `total_tokenss`
- `update` 返回两个字典：
  - `current`: 当前这次调用的 `{ "in": int, "out": int, "total": int }`
  - `totals`: 会话累计的 `{ "in": int, "out": int, "total": int }`

在 UI 层只需要把这两个数字渲染出来即可。

### 3. 运行一次审查：`run_review`

```python
from Agent.ui.service import run_review
from Agent.tool.registry import default_tool_names

def on_event(evt: dict) -> None:
    ...

final_text = run_review(
    prompt="请审查本次 PR …",
    llm_preference="auto",        # auto/glm/moonshot/mock
    tool_names=default_tool_names(),
    auto_approve=False,           # False: 仅内置安全工具自动执行；True: 全部工具自动执行
    stream_callback=on_event,     # 流式事件回调
    tool_approver=None,           # 需要人工审批时传入
)
```

函数签名：

```python
run_review(
    prompt: str,
    llm_preference: str,
    tool_names: List[str],
    auto_approve: bool,
    stream_callback: Optional[Callable[[Dict[str, Any]], None]] = None,
    tool_approver: Optional[
        Callable[[List[NormalizedToolCall]], List[NormalizedToolCall]]
    ] = None,
) -> str
```

行为说明：
- 自动从 git 收集当前 PR/staged 的 diff，上下文构建为 “Markdown + 精简 JSON”，并追加在你的 `prompt` 后面一起发给大模型。
- 根据 `tool_names` 注册工具，并把工具 schema 传给 LLM（支持工具调用）。
- 内部使用统一的 CodeReviewAgent：  
  - 模型可以一次性返回多个 `tool_calls`；  
  - Runtime 会并发执行所有等待调用的工具；  
  - 等所有工具结果写回对话后，再发起下一轮 LLM 请求。
- 内置工具默认安全，始终在自动审批白名单内，即便 `auto_approve=False` 也会直接执行；  
  非内置工具需要 `auto_approve=True` 或提供 `tool_approver` 后才会运行。
- 返回值：最终的审查文本（LLM 最后一条 assistant 消息）。

## 三、流式事件协议（给前端用）

`stream_callback` 在审查过程中会收到一系列字典事件，核心字段如下：

### 1. 普通增量：`type == "delta"`

```json
{
  "type": "delta",
  "call_index": 1,
  "content_delta": "增量文本（可能为空）",
  "tool_calls_delta": [ ... ],        // 可选：工具分片
  "usage": { ... }                    // 可选：tokens 用量
}
```

- 前端可以把 `content_delta` 直接 append 到输出区域，实现流式展示。
- 如果带有 `usage`，可以丢给 `UsageAggregator.update` 做一次统计。

### 2. 用量汇总：`type == "usage_summary"`

Agent 在每次 LLM 调用结束后，会保证补发一条 usage 汇总事件（如果模型返回了 usage）：

```json
{
  "type": "usage_summary",
  "call_index": 1,
  "usage": {
    "input_tokenss": 1234,
    "output_tokenss": 567,
    "total_tokenss": 1801
  }
}
```

使用方式和 `delta` 里的 `usage` 一样，推荐统一交给 `UsageAggregator` 来处理。

### 3. 工具审批（当 auto_approve=False 时）

`tool_approver` 的参数类型是 `List[NormalizedToolCall]`，结构类似：

```json
{
  "id": "read_file_hunk:0",
  "name": "read_file_hunk",
  "index": 0,
  "arguments": {
    "path": "DIFF/diff_collector.py",
    "start_line": 120,
    "end_line": 180,
    "before": 10,
    "after": 10
  }
}
```

前端可以在 UI 上弹窗展示 `name` + `arguments`，让用户选择允许/拒绝，然后把**允许执行的那一部分列表**作为返回值传回 `run_review`。

## 四、可用工具列表

工具统一注册在 `Agent/tool/registry.py` 中，默认暴露且自动审批的内置工具包括：

- `list_project_files`：读取项目结构（尊重 .gitignore）。  
- `list_directory`：列出指定目录下的文件和子目录。
- `read_file_hunk`：读取文件片段及上下文。  
- `read_file_info`：返回文件大小、推测语言、行数等。  
- `search_in_project`：项目内关键字搜索（基于 `git grep`）。  
- `get_dependencies`：分析依赖清单文件（requirements.txt、package.json 等）。
- `get_scanner_results`：获取静态扫描结果（需启用静态扫描功能）。返回与代码变更相关的 error 级别问题，用于辅助审查。

可选调试工具（默认不启用、不在内置白名单）：

- `echo_tool`：简单回显文本，需显式选择后使用。

前端如果要限制工具，就传入一个子集给 `tool_names` 即可。

## 五、前端最小示例（伪代码）

以一个简单的 Web 后端为例（伪代码，仅展示调用关系）：

```python
from Agent.ui.service import run_review, UsageAggregator
from Agent.tool.registry import default_tool_names

agg = UsageAggregator()

def stream_to_client(evt):
    if evt.get("type") == "usage_summary":
        current, totals = agg.update(evt["usage"], evt.get("call_index"))
        send_to_browser({"kind": "tokenss", "current": current, "totals": totals})
    elif evt.get("type") == "delta":
        if evt.get("content_delta"):
            send_to_browser({"kind": "text", "delta": evt["content_delta"]})

def review_endpoint(request):
    prompt = request.json["prompt"]
    agg.reset()
    final_text = run_review(
        prompt=prompt,
        llm_preference="auto",
        tool_names=default_tool_names(),
        auto_approve=False,  # 内置安全工具仍自动执行；未来有风险工具可切换为 True 或走审批
        stream_callback=stream_to_client,
        tool_approver=None,
    )
    return {"final": final_text}
```

前端的任务只有三个：
1. 把用户输入的 prompt 传进来；  
2. 消费 `stream_callback` 推送出来的事件，做文本流式显示和 tokens 展示；  
3. 如需要人工审批工具，提供一个 `tool_approver` 函数让用户点选后返回允许的工具列表。

其余 LLM/工具/上下文调度都由审查内核负责。这样以后你换成任意 UI 技术栈，只要依照这个接口即可复用整套审查逻辑。  

## 六、Web 接口骨架（v1 规范）

为方便 Web UI 开发，项目新增了一层极薄的 Web 服务（见 `Agent/web/server.py`），推荐按以下接口对接：

- `GET /health`  
  返回 `{"status": "ok"}`，用于探活。

- `GET /api/tools`  
  返回当前可用工具列表：`{"tools": [...], "schemas": [...]}`（schemas 来自 registry）。

- `POST /api/review/start`  
  入参 JSON：
  ```json
  {
    "prompt": "string",
    "model": "auto | glm | moonshot | mock",
    "tools": ["echo_tool", "read_file_hunk", "..."],   // 可选，默认内置工具（default_tool_names）
    "autoApprove": false                               // 可选，默认 false
  }
  ```
  响应为 **SSE 流**（`text/event-stream`），事件结构与 `run_review` 的 stream_callback 完全一致：
  - `type="delta"`：`content_delta`、`tool_calls_delta`（可选）、`usage`（可选）
  - `type="usage_summary"`：本次调用用量
  - `type="final"`：最终回复 `{ "type": "final", "content": "..." }`
  - `type="error"`：错误信息  
  > 当前 v1 简化：`autoApprove` 默认 false；内置安全工具总是自动执行，未来高风险工具可通过开启 autoApprove 或审批回调控制。

- `POST /api/review/approve-tools`（预留）  
  未来用于人工审批工具，当前可忽略或直接 200。

前端（Web）只需：
1) 调用 `GET /api/tools` 绘制工具列表；  
2) 调用 `POST /api/review/start` 建立 SSE 连接，消费事件流；  
3) 用 UsageAggregator 的思想在前端统计 tokens HUD；  
4) 将 `type="final"` 的 content 作为最终结果显示。
