# 上下文处理

## 2025-11-19

* 随着本地维护上下文消息，每次调用API导致token线性增长，尤其是工具使用上的增长直接导致token的消耗按工具调用倍数增长，于此同时我注意到即便LLM支持同时调用多个工具，但实际运行时，LLM倾向于单独调用工具，以至于成功调用工具后需要重新发起新的API请求，这不仅大量消耗token的同时还会造成不必要的浪费

* 对于上下文的长文本输入，LLM注意力机制会出现["中间迷失"](https://arxiv.org/html/2508.05128v1)和["注意力盆地"](https://arxiv.org/html/2508.05128v1)

* [ ] 目前上下文体系还是“最简单、但浪费”的实现——它能保证语义正确（不丢信息），但从“噪音控制”和“token 成本”来看，是明显需要优化的

* [x] 目前diff片段使用的是修改前的上下文+修改后的上下文进行拼接，显然这是不合理的，仅需要将修改的diff和公用的上下文进行拼接

​	`DIFF/diff_collector.py` 生成的 unified_diff 只包含修改行和必要的上下文行，不会把修改前/后的完整文本双倍塞入。

* [ ] 仅支持工具调用间的上下文传递，未支持多轮 Agent 调度时的全局状态管理。

# 模型选择

## 2025-11-20

我发现`GLM-4.6`似乎钟情于调用工具，以至于一次简单改动居然打掉十万token

## 2025-11-22

我对`GLM-4.6`,`kimi-k2-0905-preview`,`qwen3-max`进行测试，发现一个问题，似乎不同的模型对工具调用的偏好是不一样，在实际使用中`GLM-4.6`偏爱调用工具，而其他两款模型似乎不太愿意主动调用工具，并且检查具体实现并测试后这两个模型能够调用工具，只是为什么相比`GLM-4.6`调用工具差这么多

### 应对策略考量

是否将工具调用权从模型迁移到Agent的显示规划中？

# 工具兼容性

* [x] 调用工具时，如果不启用 auto_approve 且审批拒绝执行工具时，不会给LLM返回拒绝信息；
  已在 `Agent/agents/review/code_reviewer.py` 中改为生成错误工具结果，模型能收到明确拒绝原因，避免无限请求。

# 当前阶段重点（测试态，无并发）

- 并发安全（`os.chdir` 全局切换）暂不影响当前测试流程，可留作后续处理。
- 持续完善上下文优化策略：减少 diff + 对话消息的 token 成本，避免工具多轮时上下文膨胀；需要设计历史裁剪/摘要方案并落地。
