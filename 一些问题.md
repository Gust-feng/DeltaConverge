# 上下文处理

## 2025-11-19

* 随着本地维护上下文消息，每次调用API导致tokens线性增长，尤其是工具使用上的增长直接导致tokens的消耗按工具调用倍数增长，于此同时我注意到即便LLM支持同时调用多个工具，但实际运行时，LLM倾向于单独调用工具，以至于成功调用工具后需要重新发起新的API请求，这不仅大量消耗tokens的同时还会造成不必要的浪费

* 对于上下文的长文本输入，LLM注意力机制会出现["中间迷失"](https://arxiv.org/html/2508.05128v1)和["注意力盆地"](https://arxiv.org/html/2508.05128v1)

* [x] 目前上下文体系还是“最简单、但浪费”的实现——它能保证语义正确（不丢信息），但从“噪音控制”和“tokens 成本”来看，是明显需要优化的

  > 上下文使用`规则+LLM=上下文进行调度

* [x] 目前diff片段使用的是修改前的上下文+修改后的上下文进行拼接，显然这是不合理的，仅需要将修改的diff和公用的上下文进行拼接

​	`DIFF/diff_collector.py` 生成的 unified_diff 只包含修改行和必要的上下文行，不会把修改前/后的完整文本双倍塞入。

* [ ] 仅支持工具调用间的上下文传递，未支持多轮 Agent 调度时的全局状态管理。

## 2025-11-26

* [x] 规划输出未做 Schema 校验，出现 `"extra_requests [],": "kip_review"` 等脏字段仍被接受；需要按 JSON Schema 过滤/修正非法键。

  > 对提示词进行调整；对LLM返回结果进行过滤/修正

* [x] 融合阶段未真正筛选，`fuse_plan` 仍对全部 review_index.units 生成 plan，planner 的选中/去噪失效；应只保留“planner 选中 + 规则高风险/高置信度兜底”，其余默认 skip_review。

* [ ] 上下文调度存在安全隐患：`_git_show_file`/`_search_callers` 直接拼接子进程参数，缺少路径/符号白名单，需改为安全调用（规范化路径，拒绝 `..`/重定向/空格注入，或使用 `git show -- <path>`）。

* [ ] 规则层异常时 `rule_context_level` 可能为 unknown，融合/调度阶段会当正常值用；应在融合阶段兜底为 diff_only 并记录 warning，方便排查规则错误。

* [x] 可观测性不足：未记录实际下发给 LLM 的上下文大小/截断信息；`build_context_bundle` 后应写入各级上下文字符/行数、截断/降级次数。

  > 增加回退观察机制

* [ ] CodeReviewAgent 会话日志初始化缩进异常（首轮 `_trace_logger.start` 代码嵌在 `if not self.state.messages` 内），可能导致首轮漏记日志；需要整理缩进/结构。

* [ ] 规划/审查失败兜底不足：planner timeout、JSON 解析失败或 LLM 错误时，应在 pipeline 日志写明并返回可解析的空计划/错误计划，避免后续链路级联异常。

## 2025-11-26

- [ ] 现阶段每轮使用工具导致tokens消耗量剧增，平均10个文件，25-30变更消耗35万tokens。其中大部分由工具调用返回的结果消耗且呈现线性增长，是否考虑进行针对调用工具进行优化。

# 模型选择

## 2025-11-20

我发现`GLM-4.6`似乎钟情于调用工具，以至于一次简单改动居然打掉十万tokens

## 2025-11-22

我对`GLM-4.6`,`kimi-k2-0905-preview`,`qwen3-max`进行测试，发现一个问题，似乎不同的模型对工具调用的偏好是不一样，在实际使用中`GLM-4.6`偏爱调用工具，而其他两款模型似乎不太愿意主动调用工具，并且检查具体实现并测试后这两个模型能够调用工具，只是为什么相比`GLM-4.6`调用工具差这么多

### 应对策略考量

是否将工具调用权从模型迁移到Agent的显示规划中？

# 工具兼容性

* [x] 调用工具时，如果不启用 auto_approve 且审批拒绝执行工具时，不会给LLM返回拒绝信息；
  
  > 已在 `Agent/agent/agents/code_reviewer.py` 中改为生成错误工具结果，模型能收到明确拒绝原因，避免无限请求。

# 当前阶段重点（测试态，无并发）

- 并发安全（`os.chdir` 全局切换）暂不影响当前测试流程，可留作后续处理。
- 持续完善上下文优化策略：减少 diff + 对话消息的 tokens 成本，避免工具多轮时上下文膨胀；需要设计历史裁剪/摘要方案并落地。
