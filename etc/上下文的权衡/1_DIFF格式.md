# 不同 diff 形式的比较与分析

| diff 形式                           | 关键特点                                                     | 研究/实践发现                                                |
| ----------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **标准统一 diff (unified diff)**    | 使用 `---/+++` 标明旧文件和新文件，`@@ -a,b +c,d @@` 表示修改的行号范围，改变行前加 `-`、新增行前加 `+`，保留的上下文前留空。 | 是 Git 默认输出格式，训练数据中出现频繁，GPT 等模型对其格式非常熟悉。一些工具（如 *aider*）发现让 GPT‑4 生成简化的统一 diff（忽略行号）可以大幅降低“懒惰”编码和漏写代码的情况。使用统一 diff 为大模型提供了“熟悉、简单、高层次”的编辑格式，模型容易遵循。 |
| **简化的统一 diff (udiff/udiff‑h)** | 删除或放宽 hunk 头中的行号，例如使用 `@@ … @@` 代替 `@@ -a,b +c,d @@`，其余格式与标准统一 diff 相同。 | JetBrains 的 Diff‑XYZ 基准中，`udiff` 和 `udiff‑h` 在大型模型上的表现略弱于 search‑replace 格式，但仍然是可靠的选择。简化 hunk 头可以避免模型计算行号等全局约束，提高生成成功率。 |
| **带标记的统一 diff (udiff‑l)**     | 用 `ADD`、`DEL`、`CON` 等词代替 `+/-/空格` 标记，每行前不再是单字符。 | Diff‑XYZ 发现这种冗长标记使模型更难理解，性能在大多数设置下明显变差。 |
| **搜索/替换格式 (search‑replace)**  | 由一系列 `<<<<<< SEARCH`…`======`…`>>>>>> REPLACE` 块组成，每块指定要搜索的文本和替换的新文本；不包含行号。 | Diff‑XYZ 指出，对于大型 LLM，这种格式在“应用 diff”“反向应用 diff”和“生成 diff”三个任务上表现最好。它避免了行号等全局约束，只需局部匹配，模型更易生成。但它要求在原文件中精确匹配 `SEARCH` 块，否则应用会失败；Roo‑Code 项目报告这种策略容易因空白或注释不同而匹配失败，建议改用统一 diff。 |
| **Aider 的 `udiff` 变体**           | 基于 unified diff，但删除行号并鼓励输出完整代码块（高层次 diff）；以 `@@ … @@` 开头，后面是原代码与修改后的代码。 | Aider 对 GPT‑4‑Turbo 的基准测试显示，使用他们的 `udiff` 替换传统 search‑replace 块，得分从 20% 提高到 61%，懒惰注释数量减少三倍。他们建议使用模型熟悉且简单的格式，避免嵌入 JSON 或过于结构化的格式。 |
| **语义编辑 (Semantic edit)**        | 不直接输出 diff，而是描述修改意图（例如“在成功验证后调用 set_last_login(username)”)）并让后端程序解析执行。 | Morph LLM 的文章指出，传统 diff（搜索‑替换）在中大型文件上的成功率只有 60‑80%，对最近修改的代码成功率更低。语义编辑利用 AST/语义信息生成修改，准确率显著提高。这种方法需要更复杂的执行环境，但对于大型代码库更加可靠。 |

> 参考：Diff最佳实践[^1]

# 当前主流AI代码审查系统的上下文策略分析

## 标准上下文策略模型

> 许多代码审查工具直接将```上下文 = 代码文本 + diff 文本 + prompt 文本```，这种做法存在明显局限。

当前，绝大多数AI代码审查工具所采用的上下文策略可以概括为一种“三段式”模型，这个模型构成了AI进行代码审查的基础信息输入，其设计理念在于为LLM提供足够的信息来理解“发生了什么变更”（Diff）、“变更发生在何处”（代码文本）以及“需要关注什么”（Prompt指令）。这种策略的实现相对简单，易于与现有的版本控制系统（如Git）和开发工作流（如Pull Request, PR）集成，因此在早期AI代码审查工具中得到了广泛应用。然而，这种模型的简单性也为其带来了根本性的挑战，因为它往往只能提供代码变更的“快照”，而非完整的“故事”，导致LLM在缺乏深层语义和项目背景的情况下做出判断

## 核心问题

差异视图会误导审查者。它只会显示哪些代码发生了变化，而不会显示这些变化可能导致哪些问题：

- 当你向函数添加一个参数时，差异视图不会显示十二个调用点现在传递了错误数量的参数
- 当你更改返回类型时，差异视图也不会高亮显示上游代码中仍然使用旧格式的部分

> 参考：Outside Diff Impact Slicing[^2]

## 其他工具的实践：整合依赖与提交信息

- 一些先进的系统会尝试整合**代码的依赖关系**，如JavaScript项目中导入的其他模块或函数声明，以帮助LLM理解变更的潜在影响范围 
- **Git提交信息（Commit Message）** 也被视为一个有价值的上下文来源。理论上，提交信息应该简洁地描述了变更的目的，这为LLM理解开发者的意图提供了重要线索。然而，实践中发现，许多提交信息的质量参差不齐，甚至与代码变更内容不符，这使得单纯依赖提交信息来构建上下文变得不可靠 。

##  现有策略的局限性：上下文不足与噪音问题

尽管“代码 + Diff + Prompt”模型为AI代码审查奠定了基础，但其固有的局限性在实践中日益凸显，主要体现在两个方面：**上下文不足**和**信息噪音**。上下文不足导致LLM无法全面理解代码变更的深层含义和潜在影响，从而漏掉关键问题或做出错误判断。而信息噪音则表现为LLM生成大量无关紧要、过于主观或与现有工具重复的建议，这些“噪音”评论淹没了真正有价值的反馈，干扰了开发者，甚至降低了团队对AI审查工具的信任度。

- 仅依赖Diff导致的上下文缺失
- 信息过载与无关噪音干扰LLM判断

### 典型案例：GitHub  Copilot

GitHub Copilot作为AI辅助编程领域的领军者，其代码审查功能也体现了这一标准上下文策略。根据GitHub官方文档的描述，当Copilot执行代码审查时，它会将代码变更（即Diff）与相关的上下文信息（如Pull Request的标题和描述）以及用户可能提供的自定义指令整合在一起，构建一个综合性的Prompt 。这个Prompt随后被发送给底层的LLM进行分析。模型生成的反馈，包括对代码的改进建议、潜在问题的识别等，会被格式化为评论，并直接展示在Pull Request的界面上。这个流程清晰地展示了“代码变更 + 相关上下文 + 自定义指令”的模式，是标准上下文策略的典型实践。然而，这种模式的成功高度依赖于PR描述的质量和自定义指令的详尽程度，如果这些信息缺失或模糊，审查的有效性将大打折扣。

> 参考：负责任地使用 GitHub Copilot 代码审查[^3]

## 疑问

在探讨AI代码审查的上下文策略时，一个有趣的问题浮出水面：既然JSON作为一种结构化数据格式，理论上更易于被机器解析和处理，为何在Pull Request的代码审查场景中，我们几乎看不到以JSON格式作为Diff输入的实践？

# 新的diff形式（JSON+Markdown)

> LLM 并不是万能解析器，它理解能力的前提是 **训练语料出现过大量类似格式**。

在讨论如何定义新的diff形式之前，需要确定任务本身是“分析”还是“生成”

这导向大模型是理解diff vs 生成diff，这是两个不同方向

很显然，审查系统偏向于前者

## JSON的实践

假设审查系统**只分析，不生成**

模型 **不会** 产出 patch / diff

模型只做：

- 找风险 / bug
- 理解改动意图
- 评估影响范围
- 帮你决定要看哪些上下文

### 这种多层系统，JSON 有几个优势：

1. **字段语义显式**
   - `path` / `change_type` / `metrics` / `tags` / `context_level`
   - 模型不再需要从 `@@ -42,9 +43,10 @@` 里猜这些东西。
2. **方便筛选和裁剪**
   - 程序可以先按文件 / 标签 / 行数过滤，再送给 LLM
   - 比把一坨大 diff 糊给模型然后在 prompt 里说“请重点关注 XXX”要稳得多。
3. **非常适合后续 multi-agent / rule-based 的决策层**
   - 比如：只把 `priority=high`、`tags` 含 `security_sensitive` 的单元送进“安全审查 Agent”。
4. **对模型来说，JSON 比统一 diff 噪音更少**
   - 统一 diff 有大量“模型必须记住但任务本身又不需要”的语法细节
   - JSON 让它更多精力用在代码和含义本身

## Markdown的实践

对 LLM 来说，Markdown 有几个天然 buff：

- 模型训练中见过无数的 `# 标题` + `python` / `diff` 代码块
- 标题是极强的“意图提示器”，例如：
   `### 改动 1：修复 git 编码处理逻辑`
- 列表、段落结构让模型更容易“分段思考”

但它有一个硬伤：**不结构化**。
 对这种要做自动决策、自动裁剪的系统来说：

- 没法轻易问：“所有 change_type=modify 的 Python 文件改了多少行？”
- 也没法轻易在程序层面把“安全相关的 diff 单独挑出来”

所以比较健康的模式是：

> **内部用 JSON 做标准数据结构，提供给 LLM 时把其中的一小部分渲染成 Markdown。**

## 延伸

- ODSC 文中提到的“Markdown 比 JSON 更清晰、更高效、更易解析”，主要基于两个实践观察：**轻量级语法带来的 token 效率**和**用标题/代码块/XML 风格标签划分内容，降低模型的解析难度**

   > 参考：使用 XML 风格标签的结构化 Markdown 格式[^4]

- Markdown 在许多场景（文档检索、RAG、代码审查等）表现优于 JSON，因为它提供了结构化提示又不增加太多符号开销，模型能更快锁定关键信息

  > 参考：
  >
  > 提升人工智能性能：理解 Markdown 中 LLM 友好的内容[^5]
  >
  > Markdown：比 JSON 或 XML 更适合嵌入 XML[^6]

- 然而，**这种优势不是绝对的**。实验证明不同模型对格式偏好不同，GPT‑3.5 在某些任务中用 JSON 表现更好，而 GPT‑4 更喜欢 Markdown，而针对表格数据格式的大规模评测则显示，高端模型（如 GPT‑5、Gemini 2.5 等）在多种格式下都能接近 100% 的召回率；换言之，**模型越先进，对格式的差异越不敏感**。社区分享的一项测试指出，最先进的模型在 CSV、Markdown、YAML、JSON 等不同格式上的成绩几乎没有差异，只有一些较小的模型（如 Mistral、Llama 系列）在格式变化时表现明显波动

    > 参考：同一家族的模型在不同提示格式下是否表现出相似的趋势？[^7]
    
- 相比传统的 unified diff，JSON 在表达结构与语义时需要额外的键名、层级与标点，这些都会占据宝贵的 token 空间。在处理大规模 PR 时，这类冗余结构会快速累积并推高推理成本。不过从工程实践看，随着项目规模扩大，单次 PR 的实际改动量通常呈下降趋势，因此 JSON 的 token 成本并不会随项目体量等比例增长。在权衡 token 开销与审查质量后，JSON 依然能提供更清晰的语义结构，使模型更容易理解变更内容。

综上，ODSC 所说的“Markdown，unified diff 在 LLM 输入方面优于 JSON”源于实践经验和对 token 效率的分析，但从研究角度看这并非普遍真理，应视模型和任务而定。

> 从近期的研究和评测来看，随着模型规模的增大和能力提升，**对输入格式的依赖在减弱**
> 参考：结构化提示：格式如何影响人工智能性能[^8]



权衡不同信息数据后 ，针对LLM接受采用json格式

**Diff → ReviewUnit（结构化）→ JSON（LLM-friendly）→ LLM 分析 → 输出建议/解释**
 （内部语义格式）

未来修改时：

**LLM 输出 unified diff（标准 patch）→ 应用到文件**
 （外部操作格式）

#### 精度与召回率受限

大型研究指出，当前 AI 代码审查工具的有效率远低于人类，只适合作为人工审查的补充。

> 参考：大模型的最佳实践[^9]

| 原则         | 说明                                                         |
| ------------ | ------------------------------------------------------------ |
| **人机协同** | AI 是辅助工具，不能替代资深工程师的判断                      |
| **透明标注** | 明确区分 AI 生成内容与人类输入                               |
| **可配置性** | 支持通过规则/指令定制 AI 行为（如 GitHub Custom Instructions） |
| **安全优先** | 对 AI 生成代码进行二次安全扫描                               |
| **反馈闭环** | 提供“赞/踩”机制，持续优化模型                                |
| **避免幻觉** | 对复杂逻辑、边界条件保持谨慎，不盲目信任                     |

## 后期上下文优化方向

[怎么优化上下文](Z:\Agent代码审查\etc\上下文的权衡\怎么优化上下文？.md)

## 参考资料

[^1]: [Diff最佳实践](https://aider.chat/docs/unified-diffs.html#:~:text=%2A%20GPT,new%20unified%20diff%20editing%20formats)
[^2]: [Outside Diff Impact Slicing](https://arxiv.org/html/2508.18771v1#:~:text=provide%20further%20suggestions%E2%80%9D%20%E2%80%93%20a,unrelated%20to%20the%20actual%20changes)
[^3]: [负责任地使用 GitHub Copilot 代码审查](https://docs.github.com/en/copilot/responsible-use/code-review)
[^4]: [使用 XML 风格标签的结构化 Markdown 格式](https://odsc.medium.com/context-engineering-for-ai-code-reviews-fix-critical-bugs-with-outside-diff-impact-slicing-6d1ec2fc87e9)

[^5]: [提升人工智能性能：理解 Markdown 中 LLM 友好的内容 ](https://store.outrightcrm.com/blog/llm-friendly-content-in-markdown/#:~:text=,input%20and%20follow%20the%20instructions)
[^6]: [Markdown：比 JSON 或 XML 更适合嵌入 XML](https://medium.com/@kanishk.khatter/markdown-a-smarter-choice-for-embeddings-than-json-or-xml-70791ece24df)
[^7]: [同一家族的模型在不同提示格式下是否表现出相似的趋势？](https://ar5iv.labs.arxiv.org/html/2411.10541v1#:~:text=Our%20research%20into%20Large%20Language,7)
[^8]: [结构化提示：格式如何影响人工智能性能](https://mehmetbaykar.com/posts/structured-prompts-how-format-impacts-ai-performance/#:~:text=Model)
[^9]: [大模型的最佳实践](https://arxiv.org/html/2508.18771v1#:~:text=)

## 调研

[Kimi Preview](https://www.kimi.com/preview/19a9c5a5-f7b2-89b5-8000-0524f0355efb)

 [AI Code Review：用 AST 提取完整上下文的精准审查方案本文分享如何构建能看懂完整上下文的 AI Code - 掘金](https://juejin.cn/post/7564665602368012334)

